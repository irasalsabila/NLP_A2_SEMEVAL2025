{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predictions(dev_file, prediction_file, output_dir, mode=None, model=None, expected_counts=None):\n",
    "    \"\"\"\n",
    "    Processes predictions and generates language-specific files.\n",
    "    \"\"\"\n",
    "    # Read the dev dataset\n",
    "    df_dev = pd.read_csv(dev_file)\n",
    "    # display(df_dev)\n",
    "\n",
    "    # Read the prediction file\n",
    "    predictions = []\n",
    "    with open(prediction_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:  # Ensure correct format: filename and generated text\n",
    "                article_id, generated = parts\n",
    "                predictions.append({\"filename\": article_id, \"generated\": generated})\n",
    "\n",
    "    df_predictions = pd.DataFrame(predictions)\n",
    "    # display(df_predictions)\n",
    "\n",
    "    # Merge predictions with the dev dataset\n",
    "    df_combined = pd.merge(df_dev, df_predictions, on='filename', how='left')\n",
    "\n",
    "    # Filter rows with generated predictions\n",
    "    filtered_df = df_combined[df_combined['generated'].notna()]\n",
    "\n",
    "    # Check expected counts\n",
    "    if expected_counts:\n",
    "        language_counts = filtered_df['language'].value_counts()\n",
    "        for lang, expected in expected_counts.items():\n",
    "            actual = language_counts.get(lang, 0)\n",
    "            if actual != expected:\n",
    "                print(f\"Discrepancy for {lang}: Expected {expected}, Got {actual}\")\n",
    "                print(f\"Missing data for {lang}:\")\n",
    "                print(df_combined[(df_combined['language'] == lang) & (df_combined['generated'].isna())])\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate language-specific files\n",
    "    for lang, group in filtered_df.groupby('language'):\n",
    "        if mode and model:\n",
    "            lang_output_file = os.path.join(output_dir, f\"{mode}_{model}_pred_{lang}.txt\")\n",
    "        elif mode:\n",
    "            lang_output_file = os.path.join(output_dir, f\"{mode}_pred_{lang}.txt\")\n",
    "        elif model:\n",
    "            lang_output_file = os.path.join(output_dir, f\"{model}_pred_{lang}.txt\")\n",
    "        else:\n",
    "            lang_output_file = os.path.join(output_dir, f\"pred_{lang}.txt\")\n",
    "\n",
    "        group[['filename', 'generated']].to_csv(lang_output_file, sep='\\t', index=False, header=False, encoding='utf-8')\n",
    "        print(f\"Saved: {lang_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./predictions/predictions_outputs/gemma_pred_BG.txt\n",
      "Saved: ./predictions/predictions_outputs/gemma_pred_EN.txt\n",
      "Saved: ./predictions/predictions_outputs/gemma_pred_HI.txt\n",
      "Saved: ./predictions/predictions_outputs/gemma_pred_PT.txt\n"
     ]
    }
   ],
   "source": [
    "dev_file_path = './data/subtask_3_dev.csv'\n",
    "# prediction_file_path = './predictions/generated_predictions/sft_predictions.txt'\n",
    "prediction_file_path = './sub_dev/gemma/predictions.txt'\n",
    "output_directory = './predictions/predictions_outputs'\n",
    "\n",
    "process_predictions(\n",
    "    dev_file=dev_file_path,\n",
    "    prediction_file=prediction_file_path,\n",
    "    output_dir=output_directory,\n",
    "    mode=None,\n",
    "    model='gemma',\n",
    "    expected_counts={\"EN\": 30, \"HI\": 29, \"BG\": 28, \"PT\": 25}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
